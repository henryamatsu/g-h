{
  "6": {
    "id": 6,
    "title": "Headless Horseman - 3: It's Not a Bug, it's a Feature",
    "excerpt": "The end result of all my efforts: failure and disappointment. Through every iteration of the app, the model still struggles with more complex user requests. I was ready to throw in the towel when I came to a (potentially desperate) epiphany...",
    "date": "2025-10-24",
    "category": "AI",
    "tags": ["AI", "Chatbots", "D&D"],
    "readTime": "5 min read",
    "author": "Henry Matsumoto",
    "content": "<p>In my previous entry, I detailed the struggle of getting my <a target='_blank' href='https://github.com/henryamatsu/headless-horseman'>D&D game master chatbot</a> to correctly call functions to manage a character’s inventory. Since then I’ve gone through an arsenal of other approaches. I lowered the chatbot’s temperature attribute to 0 so the chatbot would always build the most likely response. I added a separate processing step where I would first ask the AI to break the user request into a series of action statements, and then fed those action statements back to the model to determine which functions to call. I repeatedly tweaked and refined the system instructions and the function descriptions. I even tried using higher-end Gemini models to see if they could more reliably parse natural language prompts into function calls.</p><p>The end result of all of this: failure and disappointment. Through every iteration of the app, the model still struggles with more complex user requests. I was ready to throw in the towel when I came to a (potentially desperate) epiphany, failure and disappointment are essential parts of D&D.</p><h2>Embracing the Spirit of the Dice Roll</h2><p>To explain what I mean by this, in the game of Dungeons & Dragons, as well as other TTRPGs, you can often fail to perform an action. You might say to the game master “I want to swing my sword at that goblin”, but instead of the GM simply giving you a thumbs up and marking the goblin as dead, the GM will tell you to roll some dice. If you roll well, you might get what you want, but if you roll poorly, you probably won’t. If you roll especially bad, and if your GM has a cruel sense of humor, you might suffer some unintended side effects.</p><p>You could, for example, try throwing a rock up into the air to bat it away with a stick, where you might expect the model would call a function to remove the rock (and only the rock) from your inventory. If you rolled poorly however, you might miss the rock, causing the rock to land at your feet, at which point perhaps neither item would be removed from your inventory. You could also roll so poorly that upon hitting the rock, your stick breaks, causing both items to be removed from your inventory.</p><p>The plan all along was to eventually incorporate variable success rates into the model’s story narration, but I’ve been stuck for a long time trying to get the model to conduct the story at a baseline level where all the user’s actions are assumed to succeed. I realize now that I need to embrace the ultimately unpredictable nature of the chatbot GM. If I can’t fix the GM’s ability to call the right functions with 100% accuracy, I have to build this inability into the game.</p><p>Every time the model fails to produce the expected output, I can simply disguise it as a failed roll. Instead of expecting the model to always parse the user request correctly, I have to instruct the model to evaluate the functions it called in response to the user request, and create a narrative explanation for how their attempted action led to the corresponding function calls. If the user says they want to shoot a bow and arrow at a goblin, and the model somehow gets it in its head to call the “dropItems” function on the character’s bow, instead of going in circles trying to diagnose how the model reached this bizarre conclusion, all I need to do is get the model to roll with its own punches and explain how, against the player’s own wishes, their character dropped their bow.</p><h2>Designing for Misfires Instead of Fighting Them</h2><p>I haven’t finished implementing this new approach, but I think it represents a mindset shift that is an important milestone in the development of this app. Even as LLMs have become more advanced, and as our knowledge of how to work with them has become more sophisticated, it’s likely they will always remain, to some extent, unpredictable. Instead of trying to work all uncertainty out of a system that is by its nature, highly unpredictable, I have to begin designing the app to handle the inevitable occasional misfires in an elegant way.</p>"
  },
  "5": {
    "id": 5,
    "title": "Why is Google Translate So Bad? An Investigation",
    "excerpt": "As someone who grew up learning broken Japanese from the combined efforts of my mom, and the bread-themed super hero Anpan-man, I’ve been an aspiring bilingual for a long time. One of the biggest breakthroughs in my journey of adult language acquisition has been, without a doubt, ChatGPT.",
    "date": "2025-09-22",
    "category": "AI",
    "tags": ["AI", "Google Translate", "Language Learning", "Japanese"],
    "readTime": "7 min read",
    "author": "Henry Matsumoto",
    "content": "<p>As someone who grew up learning broken Japanese from the combined efforts of my mom, and the bread-themed super hero Anpan-man, I’ve been an aspiring bilingual for a long time. One of the biggest breakthroughs in my journey of adult language acquisition has been, without a doubt, ChatGPT. Being able to conduct an on-demand text-based back and forth, being able to ask for in-depth explanations, alternative phrasings, and various other forms of personal tutoring has greatly accelerated my learning. I know it isn’t a perfect tool, but I’m versed just well enough in the language I’m trying to learn to tell that it’s pretty dang good.</p><p>Somehow in spite of this revolution in language technology, at the time of my writing this, Google translate, the household name in translation software, is still really, really bad. I can’t actually confirm that it’s bad for all known languages (maybe it has native fluency in Tagalog, I can neither confirm nor deny), but I can say with reasonable confidence that it’s really bad at Japanese.</p><h2>Challenges of Japanese</h2><p>To be fair, Japanese is a bit of a finicky language. One of the tricky bits is that it has three separate character systems. The first is kanji, which are essentially just Chinese characters, used for pretty much all nouns/verbs/adjectives. Then there’s hiragana, used for verb conjugation, articles, particles, and pretty much everything else. Except for of course, foreign words, which are the strict purview of the third system, katakana. Japanese has a large and ever growing number of loan words, and whenever the language adopts a new one, instead of inventing a new kanji, they choose to represent it in the simpler, phonetic system of katakana.</p><p>Interestingly, even when there is a word for something in Japanese, for one reason or another, a loan word will occasionally come into popular use. Growing up, for example, I always thought the Japanese word for milk was mi-ru-ku, until one day I realized my mom was just saying “milk” with a Japanese flair. This practice is common enough to where when I recently went on a trip to Japan with my wife and my (Japanese) father-in-law, his advice to us was that if we ever didn’t know the word for something, we could probably just say the English word and make it sound Japanese, and they’d probably understand.</p><p>Well as it happened, that was less than stellar advice, and no one knew what we were saying (except on the rare occasions when we were talking about milk.) Unfortunately, before we could provide feedback on the strategy to my father-in-law, he had already gone and shared the hack with important decision makers at Google, and they really took it to heart it seems.</p><p>What is the Japanese word for “dance” according to Google translate? Why, it’s “dan-su” of course. How about the word “help”? If you guessed “he-ru-pu”, you might just be a native Japanese speaker. These weren’t plucked from a curated list of words that Google translate happens to mistranslate, I simply typed in some common words that I knew existed natively in Japanese, and with practically every third word I was given back the English word in katakana.</p><h2>The Underpinnings of Google Translate</h2><p>This phenomenon made me extremely curious of the underlying mechanism. After doing some digging, I learned that the AI that powers Google Translate has moved through many transformations since its humble beginnings in 2004. It began as a statistical machine translation service that broke sentences into phrases that it would translate independently, until 2016 when it adopted a more sophisticated neural machine translation approach that leveraged deep learning to perform full-sentence translations.</p><p>Reading about how the system transitioned from doing phrase-based translations to sentence-based translations, I was reminded of one of the most fundamental challenges in language translation that might also tie back to the problem I was observing: context awareness. It’s a trivial task to take a single word in one language, and to look up a matching word in the dictionary of another language. In Japanese for example, if you plugged in the English word “cold” you might get “samui”. The problem is, “samui” is only appropriate for describing ambient temperature, whereas if you were describing a physical object being cold, the word would be “tsumetai”. And of course, there are a million other examples of this problem throughout all languages; a translation of a word might change depending on the context where it’s used.</p><h2>Limits of Single-Word Translation</h2><p>Ironically, even as the technology behind context-sensitive translation has progressed by leaps and bounds over the years, there is probably a relatively low ceiling to how much the naive approach of translating individual words can improve. At the end of the day, no matter how much better AI translation technology gets at picking the correct translation for a word in a provided context, it will likely never gain the power to guess at the context a user failed to provide when they ask to translate a single word. From there, it might simply provide the most common translation for the word regardless of context, or alternatively, it might base in translation off examples where that single word was used on its own as a complete sentence.</p><p>I’m not sure if there’s really any way for me to robustly investigate this, but my running theory is that Google Translate is often erroneously applying this latter approach. There are a handful of English words that have been adopted as exclamations in Japanese, such as “Fight!”, “Okay!”, and “Nice!”. Even though Japanese obviously does have native words to express the concept of niceness, if the model tries to treat every input as a complete sentence even for single-word translations, it would explain why sure enough, the translation it provides for “nice” is… Nīsu, because it thinks I’m asking about the city in France, Nice. At this point, I will end my investigation with the simple conclusion that Google translation is just really, really bad in a way that will continue to defy comprehension.</p>"
  },
  "4": {
    "id": 4,
    "title": "Headless Horseman 2: Put Down the Stick",
    "excerpt": "Giving instructions to a chatbot can sometimes feel similar to getting a dog to perform a trick. I have a sweet little dog named Zoey back at my parents' home, and the one trick she knows is to play dead.",
    "date": "2025-8-31",
    "category": "AI",
    "tags": ["AI", "Chatbots", "Native Function Calling", "D&D"],
    "readTime": "7 min read",
    "author": "Henry Matsumoto",
    "content": "<p>Giving instructions to a chatbot can sometimes feel similar to getting a dog to perform a trick. I have a sweet little dog named Zoey back at my parents’ home, and the one trick she knows is to play dead. You point a finger gun at her, stomp one foot, and say “bang!”, and she rolls over onto her back. Now, it’s anyone’s guess as to which of the three cues she’s actually responding to. I’ve tested it in various combinations and have gotten mixed results. Sometimes she seems to respond to each of the triggers in isolation, but it also seems like some parts, like the stomping, carry more weight and will elicit the behavior more consistently even on its own. It’s also possible to do all three of the actions together, and to get no response. Lastly, it’s pretty common that if you just walk up close enough to Zoey, she’ll roll onto her back for belly rubs, which might suggest that none of the intended triggers are actually as influential as simple proximity.</p><h2>Teaching My Chatbot Tricks</h2><p>I faced a similar conundrum this week as I worked on my D&D chatbot, <a target='_blank' href='https://github.com/henryamatsu/headless-horseman'>Headless Horseman</a>. I wanted to build a feature that would enable the AI to trigger function calls to update the player’s inventory when prompted with natural language. I tested it out in the following dialogue:</p><p>User: I put down my stick</p><p>Model: You discard the stick. // the model calls removeItems(“stick”, 1)</p><p>User: I pick the stick back up</p><p>Model: You pick the stick back up. // the model calls addItems(“stick”, 1)</p><p>User: I put down the stick again.</p><p>Model: You discard the stick. // the model calls no functions</p><p>I was running into an issue where the AI would perform the correct functions pretty reliably the first time around, but every second time it was asked to perform the same task in a single conversation, it would provide a verbal description of the action, without actually calling the corresponding function.</p><p>I jumped through many hoops trying to get this to work. I changed the function call configuration settings to make it so the model would always have to call at least one function in response to a prompt. This caused the opposite problem however, where the model was now calling functions when none were necessary. I then created a “callNoFunctions” function that the model could call if it deemed there were no applicable functions to call, but of course with this I had come full circle. I also invested some time into engineering better prompts, giving more detailed instructions and offering few-shot examples, but it was hard to tell if any of my efforts were getting the model any closer to providing consistent, correct output.</p><h2>Spelling it Out</h2><p>I eventually arrived on the suspicion that when the model was reading over the past conversation history, it might have been looking at older instances of the repeated instruction “I put down the stick”, and assumed that it had already completed the task, and therefore didn’t need to make a repeated function call. This theory was reinforced by another test where I would perform a textual juggling act, telling the model to put down a stick, pick up a rock, put down the rock, pick up the stick, and so on. There would be instances where I would tell the model “pick up the stick”, and it would instead pick up both items. This seemed to indicate an opposite case, where the model was looking at the old “pick up a rock” instruction that it had already completed, but would mistakenly repeat the task along with the new instruction.</p><p>To resolve this, I began storing the function results in my messages database, and started feeding them to the model as part of the chat history so that a conversation step would appear as the following:</p><p>User: I put down my stick</p><p>Model: Successfully Removed Items: [{\"name\":\"stick\",\"count\":1},</p><p>Model: You discard the stick.</p><p>This seemed to trigger the correct function calls with much greater accuracy. Now when I make repeated function calls in the same conversation, my theory is that the model is able to see a more clear log of inventory updates, and knows better when a function still needs to be performed.</p><h2>Some Number of Steps Forward, Some Number of Steps Back</h2><p>From here I moved on to a trickier instruction: “I throw the rock up in the air, and I bat it away with the stick” after which point all hell broke loose. The removeItems function gets called, but it’s called on both the rock and the stick. Or it’s called on just the rock, and then the addItems function is called to add it immediately back. Or sometimes no functions are called at all. Sometimes the model will get it exactly right, and will only call removeItems on the rock, but in all of these cases, the most glaring issue is that the model still describes the scene as if the right functions were performed: You throw the rock up in the air and bat it away with the stick.</p><p>With all of this said, I’m not sure if I am any closer to correctly implementing this feature. I felt like I had made real progress with the revelation of adding the function results to the chat history, but now I’m second guessing whether that even helped. I think it’s very easy to fall into the trap of trusting anecdotal experience when it comes to working with AI, and if the inclusion isn’t actually beneficial, or if there’s some better alternative solution, I might just be clogging up my message database for no reason. That’s the real pain I’ve felt in this process, I don’t know what aspects of my input have bearing on producing the various desired aspects of the output.</p><p>And I regret to say that, at this moment, I am still holding the stick.</p>"
  },
  "3": {
    "id": 3,
    "title": "Crane Game - 1: Robotics For Dummies (I'm the Dummy)",
    "excerpt": "I probably shouldn’t admit this, because it doesn’t lend authority to my voice as a hobbyist roboticist, but I don’t really know much about robots.",
    "date": "2025-06-30",
    "category": "Robotics",
    "tags": ["Robotics", "Microcontrollers", "Prize Crane"],
    "readTime": "6 min read",
    "author": "Henry Matsumoto",
    "content": "<p>I probably shouldn’t admit this, because it doesn’t lend authority to my voice as a hobbyist roboticist, but I don’t really know much about robots. Truthfully, even as a software engineer, I don’t know much about computer hardware. Beyond that, I didn’t do very well in physics class. I’m not exploring the hobby because it’s a natural extension of my existing technical knowledge, I’m exploring the hobby because it seems like a fun way to learn these things. And because I want to build cool robots, but that’s a given.</p><h2>Arduinos</h2><p>I fiddled around with Arduinos at first, and enjoyed testing out the various input and output devices. I made a miniature red-light-green-light simulator, where a series of LEDs would indicate when you should walk or freeze. a sonar motion sensor would end the game if you moved on red, and you’d win the game if you got close enough on green.</p><p>It was a fun project, but I still didn’t feel like I was tapping into the wow-factor that had first drawn me to microcontrollers. I wanted to build something that could move. I decided the obvious place to start was a robot arm. I went on a recent trip to Japan, where there were arcades consisting entirely of prize crane machines. I wondered what the process would be like to recreate one.</p><h2>Consulting a Non-Dummy</h2><p>I went to a robotics meetup at a local makers’ space and spoke with an expert. He showed me a similar project he had built, and laid out the different options. I could look at buying a premade kit, I could find an existing build and 3D print the parts, or I could make it with Legos. The obvious answer, and the thing that I realized was missing up until that point from my foray into amateur robotics, was Legos.</p><p>The precision of 3D printed parts was leagues above the Lego approach, but the beauty of a Lego build was the freedom to iterate. If you decided you wanted to scrap a project midway through, all the pieces you used could be reused indefinitely. If you decided you wanted your robot arm to be taller or shorter, it was an easy adjustment. If you wanted to do the same with a printed build, it would of course mean more printing, and if you made haphazard changes to a design you didn’t create and therefore might not intimately understand, there was no telling how your recalibrations might negatively affect the functionality.</p><h2>Building a Lego Robot Arm</h2><p>So I purchased a Lego kit with a separate board known as a microbit, and set to work on a robot arm using schematics that came with the kit. A stepper motor controlled the main bending motion of the crane, where DC motors controlled the rotation of the crane and the closing of the claw. A defect of the build that became immediately apparent, was that the DC motors would continue to spin even after the claw or the rotating base of the crane reached their maximum range of movement, after which any additional movement would risk damaging the motors. My mentor recommended I either get additional stepper motors to replace the DC motors, or to get sensors that I could add to the crane so it could determine when it reached its maximum range of motion.</p><h2>Just Dummy Things</h2><p>In the time before I resolved to buy some sensors, I had another idea. I wanted to see if I could build in some sort of mechanical fail-safe that would cause the gears of the claw and the crane rotation to disconnect if they ever reached their maximum range. I reaffixed the gears attached to the claw in such a way that they were held generally still, but could swivel very slightly so as to disconnect with the central gear if the motor was still pushing them to turn after they had finished closing. I came up with a similar fix for base.</p><p>The end result was a rickety mess, where the gear connections would naturally come loose if I picked up the crane and moved it too fast. If the claws came together around an object, they would often push against the object, causing the gears to come loose, and for the claw to fall slack. I had a eureka moment where I realized, this was a very natural way to implement the variable grip strength that serves as a frustrating hallmark of prize crane games, where virtually all such machines are designed to prematurely release a captured prize upwards of 80% of the time.</p><h2>Accepting Limitations and Moving Forward</h2><p>In the end however It was clear that a more refined approach with the appropriate tools would achieve a better result, and I decided to order some sensors. It’s probably a bad habit of mine, but when someone tells me I need a different tool for a job, I often spend too much time having too much fun trying to solve the problem with the mismatched tools that I already have. Hopefully by my next entry however, we will be making real progress toward DIY Japanese Prize Crane Machine.</p>"
  },
  "2": {
    "id": 2,
    "title": "Headless Horseman 1: An Introduction",
    "excerpt": "I've recently set to work at building a chatbot application, currently dubbed \"Headless Horseman\", that can act as the game master for Dungeons & Dragons and other tabletop roleplaying games like it.",
    "date": "2025-05-21",
    "category": "AI",
    "tags": ["AI", "Chatbots", "D&D"],
    "readTime": "5 min read",
    "author": "Henry Matsumoto",
    "content": "<p>I’ve recently set to work at building a <a target='_blank' href='https://github.com/henryamatsu/headless-horseman'>chatbot application</a>, currently dubbed “Headless Horseman” that can act as the game master for Dungeons & Dragons and other tabletop roleplaying games like it. In the era of video games, and endless other forms of digital entertainment, I’m aware of the obvious irony in my pursuit to replace with robots a major human component of a hobby that many of us love for the human-driven gameplay experience it provides. I’ve also found the online TTRPG community to be an extremely rich artistic ecosystem, where players will draw their own characters, sculpt their own dice, paint their own miniatures, and create their own worlds, and many of these people, I think for many good reasons, despise artificial intelligence for its encroachment on their craft, and would likely baulk at the idea of a robot game master.</p><h2>A Noble Pursuit</h2><p>All of this considered, I still believe it’s a noble pursuit. Why? Because as a lifetime enthusiast for the hobby, I want to actually be able to play Dungeons & Dragons. For those of you uninitiated, I should explain, hardly anyone actually plays Dungeons & Dragons, we just leaf through the hefty instruction manuals, imagining what it might truly feel like to make an attack roll or to perform a saving throw. Many of us own dice we’ve never actually rolled. Experiencing the game vicariously through podcasts has become a hobby in its own right. There’s one “actual play” as they’re called, that became so popular it was adapted into a multi-season Amazon Prime show.</p><p>Why don’t we actually play this game ourselves if we’re supposedly interested in it? It’s not for fear of acting or for fear of adding up the numbers on the dice, it’s just that the simple act of sitting down at a table with 3-5 other interested individuals once a week or twice a month for 2-4 hours at a time, ends up being a logistical impossibility for nearly any group of working adults. If the stars happen to align, and you have a group of friends who just might be interested in playing, and who might have just enough compatible free time to get together, then you have to surmount the final ordeal, deciding who will run the game.</p><h2>The Plight of the Unwilling Game Master</h2><p>This last step is actually very easy: it’s going to be you. If it was your idea to play D&D with your friends, chances are you are the most invested in making it happen. If you go to your friends with a quirky board game that doesn’t actually have a board, has three 700 page instruction manuals, and takes months long to play, and if your friends aren’t enthusiasts themselves, then odds are you are going to have to do the heavy lifting of actually running the game. This can mean multiple additional hours of time before each session preparing the events of the game. It means you have to overcome stage fright, writer’s block, and the fear that your friends will think the names you picked for your NPCs are dumb. The real tragedy is, after all your toil, you don’t really get to play the game, you have to run it. Running the game can be enjoyable in its own right, and there are even many people who prefer it, but to get to the crux of what this whole project is really about: I do not prefer it. I want to play D&D as one of the players. And so the options I’m left with are:</p><ul><li>Trick one of my friends into being the game master</li><li>Find different friends</li><li>Experience the game vicariously through podcasts</li><li>Form a pact with an otherworldly entity that can run the game for me and my friends (build a chatbot)</li></ul><h2>A Necessary Evil</h2><p>So maybe better than to say it’s a noble pursuit, I think it’s a necessary evil. I don’t think it’s going to rival the original works of Shakespeare, Goethe, Miguel de Cervantes, and I really writhe at the idea of AI ebbing more and more into the realm of creative writing as a whole, but at the end of the day, I just want to play my game. Updates soon to come on how the project has progressed!</p>"
  },
  "1": {
    "id": 1,
    "title": "I Will Not Use Tailwind, Sam I Am",
    "excerpt": "Spoiler Alert: I do use Tailwind in the end. But the first time I encountered it in the wild, it was revulsion at first sight.",
    "date": "2025-3-06",
    "category": "Web Dev",
    "tags": ["Web Design", "CSS", "CSS Frameworks", "Tailwind"],
    "readTime": "7 min read",
    "author": "Henry Matsumoto",
    "content": "<p>Spoiler Alert: I do use Tailwind in the end. But the first time I encountered it in the wild, it was revulsion at first sight. It’s ugly, it’s in the wrong place, it’s horizontal. These are all egregious things. I’ve heard lots of people echo these claims, and I’ve heard just as many people dismiss them.</p><p>At first glance, the most striking violation that Tailwind seems to be guilty of is how it breaks the rule of separation of concerns. CSS rules aren’t meant to be written directly inline with HTML elements. This causes visual clutter, destroys any hope of reusability, leads to countless style discrepancies between similar elements, and creates a strong coupling between the formatting and styling of a webpage. Tailwind seems to be guilty of all these things.</p><p>The first compelling argument I heard in favor of Tailwind was in a <a target='_blank' href='https://adamwathan.me/css-utility-classes-and-separation-of-concerns/'>blog post</a> by Adam Wathan, the creator of Tailwind. Instead of arguing that his approach didn’t violate the rule, he essentially said that separation of concerns was an impossible ideal that we’ve never really been able to achieve. Whether you take the approach of “semantic” CSS, where elements are assigned classes that describe the element’s purpose, or “functional” CSS, where elements are assigned classes that describe the element’s styling, by the former approach the design of your CSS will depend on the design or your HTML, and in the latter approach the design of your HTML will depend on your CSS. If in either case the two are inseparably intertwined, we should stop using their “separation” as an important criterion for how to do good web design, and should instead focus on other things.</p><h2>Reusability</h2><p>When we compare the two approaches on the axis of reusability, functional CSS is the obvious winner. If you give elements classes based on their purpose, even if two elements incidentally have near identical styling, they won’t be able to share the same class since they still serve different purposes. By taking the functional approach, we can define a class instead that describes their shared styles, and apply the class to both.</p><p>When this approach is taken to its logical conclusion, we end up with increasingly modular classes. You could wrap style-rules together into small related packages, but if a specific combination of rules is only going to be used so many times throughout your codebase, or if you frequently need to work in adjustments for exceptional cases, at some point all such systems would probably arrive at the more or less 1:1 class to style rule design of Tailwind. This leads to its own new problems that we will discuss below, but it’s important to remember that this design was introduced as a solution to an existing issue.</p><h2>Consistency</h2><p>One of the claims I’m the most suspicious of with systems like Tailwind, is that it will reduce the ever growing assortment of style discrepancies that are found throughout virtually any large codebase. When I first started using Tailwind, I found the reduced variety of options for things like padding/border/margin sizes frustrating, because it meant you had less granular control, but when I heard it described as a necessary guardrail to keep those values consistent throughout a codebase, it seemed like a justified tradeoff.</p><p>The idea however that the introduction of infinitely modular single-rule utility classes written out directly in the class attribute of HTML elements wouldn’t lead to at least a comparably egregious level of style drift I find hard to believe. Wathan does himself advocate for comprising individual utility classes together for commonly reused elements like buttons, but the fact that the default approach of Tailwind is to mix and match utility classes, instead of looking up previously built component classes, I have to imagine many ideally identical elements throughout a Tailwind codebase will end up with a slightly different assortment of style rules applied to them.</p><h2>Collaboration</h2><p>I think the strongest argument for Tailwind and other similar CSS frameworks, is the shared language they create. Every developer on a team is going to end up having their own personal intuitions about what a class should be called, when to give an element its own class name or to use a combinator, and so on. By agreeing to a rigid set of class names that are used throughout as well as across codebases, we can simplify the work of deciphering the countless contrasting design philosophies that converge within any frontend team.</p><h2>Aesthetics</h2><p>In all of my investigation into the pros of adopting a system like Tailwind, I’ve really had to suspend my disbelief that they all might justify the one most glaring con, the fact that tailwind classes, trailing horizontally across the page into infinity, are just really, really ugly. I’ve heard people describe this as an insignificant concern that just comes down to taste, but I feel like it has a strong tie to the consistency issue as described above, it creates clutter among other attributes in an element’s opening tag, and ultimately sequesters the workspace of the style-concerned frontend dev to the tiny little box that is the HTML element’s class attribute.</p><p>Before, if you took on the task of styling a webpage, you had the whole canvas of a CSS file to work with, you could arrange declaration blocks as you saw fit, you could add comments, you could easily troubleshoot styling issues by commenting out lines. Now you need to scroll horizontally through a single string of abbreviated style rules directly on your HTML page. I think this problem extends well beyond an issue of simply aesthetic preference, and the underlying issue is that the process of writing vanilla CSS is much more user friendly then typing out Tailwind classes.</p><h2>Conclusion</h2><p>After all my analysis is said and done, I will of course use Tailwind. It definitely has its drawbacks, but no new technology or innovation is ever a 100% improvement over its predecessor. I haven’t been in this industry long enough to dig my heels or die on some hill to avoid using a new, unfamiliar (and therefore, scary and bad) technology that lots of other reasonable people seem to get a lot of value from. I’m still in (and will hopefully forever remain) in the phase of my career where I can trust that, if other people really like some new tool or trend, I can move past my negative kneejerk reaction, and open my mind to the possibility of how it might make my life better as well.</p>"
  }
}
